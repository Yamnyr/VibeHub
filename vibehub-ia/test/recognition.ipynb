{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (6.0.0)\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly) (1.30.0)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from plotly) (24.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from seaborn) (1.24.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/charly/Library/Python/3.11/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/charly/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-12 14:20:20.514527: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "%pip install plotly seaborn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import confusion_matrix , classification_report \n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"../input/emotion-detection-fer/train\"\n",
    "test_dir = \"../input/emotion-detection-fer/test\"\n",
    "\n",
    "SEED = 12\n",
    "IMG_HEIGHT = 48\n",
    "IMG_WIDTH = 48\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "FINE_TUNING_EPOCHS = 20\n",
    "LR = 0.01\n",
    "NUM_CLASSES = 7\n",
    "EARLY_STOPPING_CRITERIA=3\n",
    "CLASS_LABELS  = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', \"Surprise\"]\n",
    "CLASS_LABELS_EMOJIS = [\"ðŸ‘¿\", \"ðŸ¤¢\" , \"ðŸ˜±\" , \"ðŸ˜Š\" , \"ðŸ˜ \", \"ðŸ˜”\" , \"ðŸ˜²\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/emotion-detection-fer/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m      3\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m                                    width_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m      5\u001b[0m                                    height_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m                                    preprocessing_function\u001b[38;5;241m=\u001b[39mpreprocess_fun\n\u001b[1;32m      9\u001b[0m                                   )\n\u001b[1;32m     10\u001b[0m test_datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(rescale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m,\n\u001b[1;32m     11\u001b[0m                                   validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     12\u001b[0m                                   preprocessing_function\u001b[38;5;241m=\u001b[39mpreprocess_fun)\n\u001b[0;32m---> 14\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mIMG_HEIGHT\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mIMG_WIDTH\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrgb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                                                    \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m12\u001b[39;49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                                   \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m validation_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(directory \u001b[38;5;241m=\u001b[39m train_dir,\n\u001b[1;32m     25\u001b[0m                                                          target_size \u001b[38;5;241m=\u001b[39m (IMG_HEIGHT ,IMG_WIDTH),\n\u001b[1;32m     26\u001b[0m                                                          batch_size \u001b[38;5;241m=\u001b[39m BATCH_SIZE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                          seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[1;32m     32\u001b[0m                                                         )\n\u001b[1;32m     34\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m test_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(directory \u001b[38;5;241m=\u001b[39m test_dir,\n\u001b[1;32m     35\u001b[0m                                                    target_size \u001b[38;5;241m=\u001b[39m (IMG_HEIGHT ,IMG_WIDTH),\n\u001b[1;32m     36\u001b[0m                                                     batch_size \u001b[38;5;241m=\u001b[39m BATCH_SIZE,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m                                                     seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[1;32m     41\u001b[0m                                                   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/preprocessing/image.py:1648\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1564\u001b[0m     directory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1578\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1579\u001b[0m ):\n\u001b[1;32m   1580\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m   1581\u001b[0m \n\u001b[1;32m   1582\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;124;03m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1660\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/preprocessing/image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[1;32m    562\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m    564\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[1;32m    565\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/emotion-detection-fer/train'"
     ]
    }
   ],
   "source": [
    "preprocess_fun = tf.keras.applications.densenet.preprocess_input\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.05,\n",
    "                                   rescale = 1./255,\n",
    "                                   validation_split = 0.2,\n",
    "                                   preprocessing_function=preprocess_fun\n",
    "                                  )\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  validation_split = 0.2,\n",
    "                                  preprocessing_function=preprocess_fun)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = True , \n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    subset = \"training\",\n",
    "                                                    seed = 12\n",
    "                                                   )\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                         target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                         batch_size = BATCH_SIZE,\n",
    "                                                         shuffle  = True , \n",
    "                                                         color_mode = \"rgb\",\n",
    "                                                         class_mode = \"categorical\",\n",
    "                                                         subset = \"validation\",\n",
    "                                                         seed = 12\n",
    "                                                        )\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(directory = test_dir,\n",
    "                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = False , \n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    seed = 12\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "def display_one_image(image, title, subplot, color):\n",
    "    plt.subplot(subplot)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image)\n",
    "    plt.title(title, fontsize=16)\n",
    "    \n",
    "def display_nine_images(images, titles, title_colors=None):\n",
    "    subplot = 331\n",
    "    plt.figure(figsize=(13,13))\n",
    "    for i in range(9):\n",
    "        color = 'black' if title_colors is None else title_colors[i]\n",
    "        display_one_image(images[i], titles[i], 331+i, color)\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "\n",
    "def image_title(label, prediction):\n",
    "  # Both prediction (probabilities) and label (one-hot) are arrays with one item per class.\n",
    "    class_idx = np.argmax(label, axis=-1)\n",
    "    prediction_idx = np.argmax(prediction, axis=-1)\n",
    "    if class_idx == prediction_idx:\n",
    "        return f'{CLASS_LABELS[prediction_idx]} [correct]', 'black'\n",
    "    else:\n",
    "        return f'{CLASS_LABELS[prediction_idx]} [incorrect, should be {CLASS_LABELS[class_idx]}]', 'red'\n",
    "\n",
    "def get_titles(images, labels, model):\n",
    "    predictions = model.predict(images)\n",
    "    titles, colors = [], []\n",
    "    for label, prediction in zip(classes, predictions):\n",
    "        title, color = image_title(label, prediction)\n",
    "        titles.append(title)\n",
    "        colors.append(color)\n",
    "    return titles, colors\n",
    "\n",
    "img_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "img_generator = img_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                   target_size = (IMG_HEIGHT ,IMG_WIDTH),\n",
    "                                                    batch_size = BATCH_SIZE,\n",
    "                                                    shuffle  = True , \n",
    "                                                    color_mode = \"rgb\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    seed = 12\n",
    "                                                  )\n",
    "clear_output()\n",
    "\n",
    "images, classes = next(img_generator)\n",
    "class_idxs = np.argmax(classes, axis=-1) \n",
    "labels = [CLASS_LABELS[idx] for idx in class_idxs]\n",
    "display_nine_images(images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(x = CLASS_LABELS_EMOJIS,\n",
    "             y = [list(train_generator.classes).count(i) for i in np.unique(train_generator.classes)] , \n",
    "             color = np.unique(train_generator.classes) ,\n",
    "             color_continuous_scale=\"Emrld\") \n",
    "fig.update_xaxes(title=\"Emotions\")\n",
    "fig.update_yaxes(title = \"Number of Images\")\n",
    "fig.update_layout(showlegend = True,\n",
    "    title = {\n",
    "        'text': 'Train Data Distribution ',\n",
    "        'y':0.95,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extractor(inputs):\n",
    "    feature_extractor = tf.keras.applications.DenseNet169(input_shape=(IMG_HEIGHT,IMG_WIDTH, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights=\"imagenet\")(inputs)\n",
    "    \n",
    "    return feature_extractor\n",
    "\n",
    "def classifier(inputs):\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    x = tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer = tf.keras.regularizers.l2(0.01))(x)\n",
    "    x = tf.keras.layers.Dropout(0.5) (x)\n",
    "    x = tf.keras.layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"classification\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def final_model(inputs):\n",
    "    densenet_feature_extractor = feature_extractor(inputs)\n",
    "    classification_output = classifier(densenet_feature_extractor)\n",
    "    \n",
    "    return classification_output\n",
    "\n",
    "def define_compile_model():\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=(IMG_HEIGHT ,IMG_WIDTH,3))\n",
    "    classification_output = final_model(inputs) \n",
    "    model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n",
    "     \n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(0.1), \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = define_compile_model()\n",
    "clear_output()\n",
    "\n",
    "# Feezing the feature extraction layers\n",
    "model.layers[1].trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStoppingCallback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                         patience=EARLY_STOPPING_CRITERIA,\n",
    "                                                         verbose= 1 ,\n",
    "                                                         restore_best_weights=True\n",
    "                                                        )\n",
    "\n",
    "history = model.fit(x = train_generator,\n",
    "                    epochs = EPOCHS ,\n",
    "                    validation_data = validation_generator , \n",
    "                    callbacks= [earlyStoppingCallback])\n",
    "\n",
    "history = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-Freezing the feature extraction layers for fine tuning \n",
    "model.layers[1].trainable = True\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(0.001), #lower learning rate\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "history_ = model.fit(x = train_generator,epochs = FINE_TUNING_EPOCHS ,validation_data = validation_generator)\n",
    "history = history.append(pd.DataFrame(history_.history) , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = px.line(data_frame= history , y= [\"accuracy\" , \"val_accuracy\"] ,markers = True )\n",
    "x.update_xaxes(title=\"Number of Epochs\")\n",
    "x.update_yaxes(title = \"Accuracy\")\n",
    "x.update_layout(showlegend = True,\n",
    "    title = {\n",
    "        'text': 'Accuracy vs Number of Epochs',\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = px.line(data_frame= history , \n",
    "            y= [\"loss\" , \"val_loss\"] , markers = True )\n",
    "x.update_xaxes(title=\"Number of Epochs\")\n",
    "x.update_yaxes(title = \"Loss\")\n",
    "x.update_layout(showlegend = True,\n",
    "    title = {\n",
    "        'text': 'Loss vs Number of Epochs',\n",
    "        'y':0.94,\n",
    "        'x':0.5,\n",
    "        'xanchor': 'center',\n",
    "        'yanchor': 'top'})\n",
    "x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)\n",
    "preds = model.predict(test_generator)\n",
    "y_preds = np.argmax(preds , axis = 1 )\n",
    "y_test = np.array(test_generator.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_data = confusion_matrix(y_test , y_preds)\n",
    "cm = pd.DataFrame(cm_data, columns=CLASS_LABELS, index = CLASS_LABELS)\n",
    "cm.index.name = 'Actual'\n",
    "cm.columns.name = 'Predicted'\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.title('Confusion Matrix', fontsize = 20)\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(cm, cbar=False, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16}, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, c_ax = plt.subplots(1,1, figsize = (15,8))\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    for (idx, c_label) in enumerate(CLASS_LABELS):\n",
    "        fpr, tpr, thresholds = roc_curve(y_test[:,idx].astype(int), y_pred[:,idx])\n",
    "        c_ax.plot(fpr, tpr,lw=2, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\n",
    "    c_ax.plot(fpr, fpr, 'black',linestyle='dashed', lw=4, label = 'Random Guessing')\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "print('ROC AUC score:', multiclass_roc_auc_score(y_test , preds  , average = \"micro\"))\n",
    "plt.xlabel('FALSE POSITIVE RATE', fontsize=18)\n",
    "plt.ylabel('TRUE POSITIVE RATE', fontsize=16)\n",
    "plt.legend(fontsize = 11.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC-AUC Score  = \" ,roc_auc_score(to_categorical(y_test) , preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
